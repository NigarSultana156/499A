{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPr7pQ5n1KJYKTC9ISbAn4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NigarSultana156/499A/blob/main/objectDetectionRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSwNJfkAXrfE",
        "outputId": "18ebf870-cdec-4f95-cb7c-f8b17b068c12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r15hcLpfVUzX",
        "outputId": "fa11ea66-228d-4e6f-ec8e-9d1f8ebe24fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: /content/extracted_files and /content/extracted_files\n"
          ]
        }
      ],
      "source": [
        "# Paths for videos and dataset\n",
        "video_paths = [\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam1_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam2_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam3_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam5_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam6_1hour.mp4'\n",
        "]\n",
        "\n",
        "# Extract ZIP file for labeled images\n",
        "zip_file_path = '/content/drive/MyDrive/top-view-multi-person-tracking-2020/labeled_images/train.zip'\n",
        "extraction_path = '/content/extracted_files'\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "test_zip_file_path = '/content/drive/MyDrive/top-view-multi-person-tracking-2020/labeled_images/test.zip'\n",
        "test_extraction_path = '/content/extracted_files'\n",
        "os.makedirs(test_extraction_path, exist_ok=True)\n",
        "with zipfile.ZipFile(test_zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(test_extraction_path)\n",
        "\n",
        "print(\"Files extracted to:\", extraction_path, \"and\", test_extraction_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images and labels\n",
        "def load_data(folder_path):\n",
        "    images, labels = [], []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        image = cv2.imread(img_path)\n",
        "        bbox = []  # Replace with actual bounding box coordinates\n",
        "        images.append(image)\n",
        "        labels.append(bbox)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load train and test data\n",
        "train_images, train_labels = load_data(extraction_path)\n",
        "test_images, test_labels = load_data(test_extraction_path)\n",
        "\n",
        "# Split train data into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "z5OJRcBoWbwe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load Faster R-CNN model from TensorFlow Hub\n",
        "model = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\")\n"
      ],
      "metadata": {
        "id": "D8C4vLj9Wb63"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(frame):\n",
        "    # Convert the frame to a tensor\n",
        "    input_tensor = tf.convert_to_tensor([frame], dtype=tf.uint8)\n",
        "\n",
        "    # Run detection\n",
        "    detections = model(input_tensor)\n",
        "\n",
        "    # Process the detection results\n",
        "    boxes = detections[\"detection_boxes\"].numpy()[0]\n",
        "    scores = detections[\"detection_scores\"].numpy()[0]\n",
        "    classes = detections[\"detection_classes\"].numpy()[0]\n",
        "\n",
        "    # Filter detections with a high confidence score\n",
        "    detection_threshold = 0.5\n",
        "    filtered_boxes = boxes[scores >= detection_threshold]\n",
        "\n",
        "    # Draw bounding boxes on the frame\n",
        "    for box in filtered_boxes:\n",
        "        ymin, xmin, ymax, xmax = box\n",
        "        start_point = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))\n",
        "        end_point = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n",
        "        frame = cv2.rectangle(frame, start_point, end_point, (255, 0, 0), 2)\n",
        "\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "IVpRp7HLXppP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captures = [cv2.VideoCapture() for _ in video_paths]\n",
        "for i, capture in enumerate(captures):\n",
        "    capture.open(video_paths[i])\n",
        "    assert capture.isOpened()\n",
        "\n",
        "im_width = int(captures[0].get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "im_height = int(captures[0].get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out_size = (im_width * 3, im_height * 2)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "out = cv2.VideoWriter('/content/output_with_detection.avi', fourcc, 20, out_size)\n",
        "\n",
        "num_frames = 1000\n",
        "\n",
        "while num_frames > 0:\n",
        "    cam1, cam2, cam3, cam4, cam5 = [capture.retrieve()[1] for capture in captures if capture.grab()]\n",
        "\n",
        "    # Apply detection on each frame\n",
        "    cam1 = detect_objects(cam1)\n",
        "    cam2 = detect_objects(cam2)\n",
        "    cam3 = detect_objects(cam3)\n",
        "    cam4 = detect_objects(cam4)\n",
        "    cam5 = detect_objects(cam5)\n",
        "\n",
        "    shape1 = list(cam1.shape)\n",
        "    shape1[1] = 160\n",
        "    shape2 = list(cam1.shape)\n",
        "    shape2[1] = 1280 - 160\n",
        "\n",
        "    upper = np.hstack((np.zeros(shape1), cam4, cam5, np.zeros(shape2)))\n",
        "    lower = np.hstack((cam1, cam2, cam3))\n",
        "\n",
        "    merged_frame = np.vstack((upper, lower))\n",
        "    out.write(np.uint8(merged_frame))\n",
        "\n",
        "    if num_frames % 100 == 0:\n",
        "        print(\"Left to merge %d frames\" % num_frames)\n",
        "\n",
        "    num_frames -= 1\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brhJN4h1CRbz",
        "outputId": "dd31691d-e71b-499c-c6a7-4aa28d64e87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left to merge 1000 frames\n",
            "Left to merge 900 frames\n",
            "Left to merge 800 frames\n",
            "Left to merge 700 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/output_with_detection.avi -vcodec libx264 /content/output_with_detection.mp4"
      ],
      "metadata": {
        "id": "jopLtHDJCRXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/output_with_detection.mp4')\n"
      ],
      "metadata": {
        "id": "ZsyZdFePCXQK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}