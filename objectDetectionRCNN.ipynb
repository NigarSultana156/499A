{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOO3sLurk0fBmUXpU6GvSJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NigarSultana156/499A/blob/main/objectDetectionRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R9IqmTpZV3Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSwNJfkAXrfE",
        "outputId": "18ebf870-cdec-4f95-cb7c-f8b17b068c12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r15hcLpfVUzX",
        "outputId": "fa11ea66-228d-4e6f-ec8e-9d1f8ebe24fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: /content/extracted_files and /content/extracted_files\n"
          ]
        }
      ],
      "source": [
        "# Paths for videos and dataset\n",
        "video_paths = [\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam1_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam2_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam3_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam5_1hour.mp4',\n",
        "    '/content/drive/MyDrive/top-view-multi-person-tracking-2020/cam6_1hour.mp4'\n",
        "]\n",
        "\n",
        "# Extract ZIP file for labeled images\n",
        "zip_file_path = '/content/drive/MyDrive/top-view-multi-person-tracking-2020/labeled_images/train.zip'\n",
        "extraction_path = '/content/extracted_files'\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "test_zip_file_path = '/content/drive/MyDrive/top-view-multi-person-tracking-2020/labeled_images/test.zip'\n",
        "test_extraction_path = '/content/extracted_files'\n",
        "os.makedirs(test_extraction_path, exist_ok=True)\n",
        "with zipfile.ZipFile(test_zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(test_extraction_path)\n",
        "\n",
        "print(\"Files extracted to:\", extraction_path, \"and\", test_extraction_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images and labels\n",
        "def load_data(folder_path):\n",
        "    images, labels = [], []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        image = cv2.imread(img_path)\n",
        "        bbox = []  # Replace with actual bounding box coordinates\n",
        "        images.append(image)\n",
        "        labels.append(bbox)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load train and test data\n",
        "train_images, train_labels = load_data(extraction_path)\n",
        "test_images, test_labels = load_data(test_extraction_path)\n",
        "\n",
        "# Split train data into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "z5OJRcBoWbwe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load Faster R-CNN model from TensorFlow Hub\n",
        "model = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\")\n"
      ],
      "metadata": {
        "id": "D8C4vLj9Wb63"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(frame):\n",
        "    # Convert the frame to a tensor\n",
        "    input_tensor = tf.convert_to_tensor([frame], dtype=tf.uint8)\n",
        "\n",
        "    # Run detection\n",
        "    detections = model(input_tensor)\n",
        "\n",
        "    # Process the detection results\n",
        "    boxes = detections[\"detection_boxes\"].numpy()[0]\n",
        "    scores = detections[\"detection_scores\"].numpy()[0]\n",
        "    classes = detections[\"detection_classes\"].numpy()[0]\n",
        "\n",
        "    # Filter detections with a high confidence score\n",
        "    detection_threshold = 0.5\n",
        "    filtered_boxes = boxes[scores >= detection_threshold]\n",
        "\n",
        "    # Draw bounding boxes on the frame\n",
        "    for box in filtered_boxes:\n",
        "        ymin, xmin, ymax, xmax = box\n",
        "        start_point = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))\n",
        "        end_point = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n",
        "        frame = cv2.rectangle(frame, start_point, end_point, (255, 0, 0), 2)\n",
        "\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "IVpRp7HLXppP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captures = [cv2.VideoCapture() for _ in video_paths]\n",
        "for i, capture in enumerate(captures):\n",
        "    capture.open(video_paths[i])\n",
        "    assert capture.isOpened()\n",
        "\n",
        "im_width = int(captures[0].get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "im_height = int(captures[0].get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out_size = (im_width * 3, im_height * 2)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "out = cv2.VideoWriter('/content/output_with_detection.avi', fourcc, 20, out_size)\n",
        "\n",
        "num_frames = 1000\n",
        "\n",
        "while num_frames > 0:\n",
        "    cam1, cam2, cam3, cam4, cam5 = [capture.retrieve()[1] for capture in captures if capture.grab()]\n",
        "\n",
        "    # Apply detection on each frame\n",
        "    cam1 = detect_objects(cam1)\n",
        "    cam2 = detect_objects(cam2)\n",
        "    cam3 = detect_objects(cam3)\n",
        "    cam4 = detect_objects(cam4)\n",
        "    cam5 = detect_objects(cam5)\n",
        "\n",
        "    shape1 = list(cam1.shape)\n",
        "    shape1[1] = 160\n",
        "    shape2 = list(cam1.shape)\n",
        "    shape2[1] = 1280 - 160\n",
        "\n",
        "    upper = np.hstack((np.zeros(shape1), cam4, cam5, np.zeros(shape2)))\n",
        "    lower = np.hstack((cam1, cam2, cam3))\n",
        "\n",
        "    merged_frame = np.vstack((upper, lower))\n",
        "    out.write(np.uint8(merged_frame))\n",
        "\n",
        "    if num_frames % 100 == 0:\n",
        "        print(\"Left to merge %d frames\" % num_frames)\n",
        "\n",
        "    num_frames -= 1\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brhJN4h1CRbz",
        "outputId": "2d5bf374-6b54-49c6-a9e4-434e886cf996"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Left to merge 1000 frames\n",
            "Left to merge 900 frames\n",
            "Left to merge 800 frames\n",
            "Left to merge 700 frames\n",
            "Left to merge 600 frames\n",
            "Left to merge 500 frames\n",
            "Left to merge 400 frames\n",
            "Left to merge 300 frames\n",
            "Left to merge 200 frames\n",
            "Left to merge 100 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/output_with_detection.avi -vcodec libx264 /content/output_with_detection.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jopLtHDJCRXV",
        "outputId": "f5847a74-093b-48e0-c317-2d623185f016"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, avi, from '/content/output_with_detection.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:50.00, start: 0.000000, bitrate: 146600 kb/s\n",
            "  Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 3840x1920, 146732 kb/s, 20 fps, 20 tbr, 20 tbn, 20 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mprofile High, level 5.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=20 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/output_with_detection.mp4':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 3840x1920, q=2-31, 20 fps, 10240 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "frame= 1000 fps=2.2 q=-1.0 Lsize=   90266kB time=00:00:49.85 bitrate=14833.6kbits/s speed=0.111x    \n",
            "video:90252kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.015365%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mframe I:4     Avg QP:17.34  size:757642\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mframe P:252   Avg QP:21.72  size:279555\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mframe B:744   Avg QP:26.31  size: 25456\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mconsecutive B-frames:  0.8%  0.0%  0.0% 99.2%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mmb I  I16..4: 19.7% 76.3%  3.9%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mmb P  I16..4:  0.4%  5.4%  0.7%  P16..4: 30.3% 22.0% 18.2%  0.0%  0.0%    skip:22.9%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mmb B  I16..4:  0.1%  0.3%  0.1%  B16..8: 25.9%  2.8%  0.5%  direct: 0.9%  skip:69.3%  L0:43.8% L1:46.2% BI:10.0%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0m8x8 transform intra:76.8% inter:80.2%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mcoded y,uvDC,uvAC intra: 80.7% 67.9% 15.3% inter: 16.4% 15.3% 1.4%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mi16 v,h,dc,p: 47% 44%  4%  6%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 27% 33%  3%  4%  4%  4%  4%  5%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 31% 28% 13%  4%  6%  5%  5%  4%  4%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mi8c dc,h,v,p: 36% 33% 27%  4%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mref P L0: 41.5% 16.2% 35.3%  7.0%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mref B L0: 80.8% 16.6%  2.6%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mref B L1: 96.1%  3.9%\n",
            "\u001b[1;36m[libx264 @ 0x58fa0e234d80] \u001b[0mkb/s:14786.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/output_with_detection.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZsyZdFePCXQK",
        "outputId": "775a9626-4bff-4133-e88d-42d53cc56738"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_59067aac-4543-41bf-b076-62763539aca7\", \"output_with_detection.mp4\", 92432271)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}