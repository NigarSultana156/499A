{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad25937-4b1a-4b6c-8ae1-94ed6370577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from IPython.display import clear_output\n",
    "!pip install tensorflow tensorflow_hub opencv-python-headless matplotlib kagglehub\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cfa37ca-352e-45ea-9ced-7b78776ed506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fb6478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image directory exists: True\n",
      "Annotation directory exists: True\n",
      "Calibration directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "dataset_path = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/aryashah2k/large-scale-multicamera-detection-dataset/versions/1/Wildtrack\"\n",
    "image_dir = os.path.join(dataset_path, \"Image_subsets\")\n",
    "annotation_dir = os.path.join(dataset_path, \"annotations_positions\")\n",
    "calibration_dir = os.path.join(dataset_path, \"calibrations\")\n",
    "\n",
    "# Check paths\n",
    "print(\"Image directory exists:\", os.path.exists(image_dir))\n",
    "print(\"Annotation directory exists:\", os.path.exists(annotation_dir))\n",
    "print(\"Calibration directory exists:\", os.path.exists(calibration_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ea48d8-484f-48ae-9ce6-6e8d6085daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 46901085369920298\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730794004.718793    2582 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d4a492-a090-4da4-9e78-d6ce4086978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "W0000 00:00:1730793577.552737   33934 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Load the Faster R-CNN model from TensorFlow Hub\n",
    "detector = hub.load(\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac1462e7-312d-42f0-8237-2c42677382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to process an image and run detection\n",
    "def detect_objects_in_image(image):\n",
    "    # Convert the image to tensor and expand dimensions\n",
    "    image_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)\n",
    "    image_tensor = tf.image.resize(image_tensor, (640, 640))\n",
    "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "    \n",
    "    # Run object detection\n",
    "    detections = detector.signatures['default'](image_tensor)\n",
    "    \n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b76cae0-4848-46b9-bb62-c9ef17481cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730792576.769439    7105 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -2484 } dim { size: -2485 } dim { size: -2486 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -105 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -105 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2649 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -105 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'num_detections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m detections \u001b[38;5;241m=\u001b[39m detect_objects_in_image(image)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m image_with_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_boxes_on_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Resize if needed and write to video\u001b[39;00m\n\u001b[1;32m     23\u001b[0m image_with_boxes_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image_with_boxes, (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m))\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mdraw_boxes_on_image\u001b[0;34m(image, detections, threshold)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_boxes_on_image\u001b[39m(image, detections, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m     14\u001b[0m     height, width, _ \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[43mdetections\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_detections\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)):\n\u001b[1;32m     16\u001b[0m         confidence \u001b[38;5;241m=\u001b[39m detections[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_detections'"
     ]
    }
   ],
   "source": [
    "# Specify camera folders and output video path\n",
    "camera_folders = [os.path.join(image_dir, f\"C{i+1}\") for i in range(7)]\n",
    "output_video_path = os.path.join(dataset_path, \"detection_output.mp4\")\n",
    "\n",
    "# Define video writer for saving output\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 5, (640, 480))\n",
    "\n",
    "# Process each frame in each camera folder\n",
    "for cam_folder in camera_folders:\n",
    "    image_files = sorted([f for f in os.listdir(cam_folder) if f.endswith('.png')])\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(cam_folder, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Detect objects\n",
    "        detections = detect_objects_in_image(image)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        image_with_boxes = draw_boxes_on_image(image, detections)\n",
    "        \n",
    "        # Resize if needed and write to video\n",
    "        image_with_boxes_resized = cv2.resize(image_with_boxes, (640, 480))\n",
    "        out.write(image_with_boxes_resized)\n",
    "\n",
    "out.release()\n",
    "print(\"Output video saved at:\", output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 5, (640, 480))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect objects\n",
    "        detections = detect_objects_in_image(frame)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        frame_with_boxes = draw_boxes_on_image(frame, detections)\n",
    "        \n",
    "        # Resize if needed and write to video\n",
    "        frame_with_boxes_resized = cv2.resize(frame_with_boxes, (640, 480))\n",
    "        out.write(frame_with_boxes_resized)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Processed video saved at:\", output_video_path)\n",
    "\n",
    "# Example usage:\n",
    "process_video(\"path/to/new_video.mp4\", \"path/to/output_new_video.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
